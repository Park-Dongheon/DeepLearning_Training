{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea3b98eb-7c2c-444b-b5ea-c66e9c4ab3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import LSTM\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c26c46f7-e4d3-4adb-89df-641556909996",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45d25667-0979-40f2-be9d-3ca699e5dc5d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 253 entries, 2019-12-11 to 2020-12-10\n",
      "Data columns (total 6 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   Open       253 non-null    float64\n",
      " 1   High       253 non-null    float64\n",
      " 2   Low        253 non-null    float64\n",
      " 3   Close      253 non-null    float64\n",
      " 4   Adj Close  253 non-null    float64\n",
      " 5   Volume     253 non-null    float64\n",
      "dtypes: float64(6)\n",
      "memory usage: 13.8 KB\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('data/SBUX.csv', index_col=[\"Date\"], date_format=\"%Y-%m-%d\")\n",
    "data[\"Volume\"] = data[\"Volume\"].astype(float)\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d39226f-dae9-4182-9a36-f58245bae73e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Open        High         Low       Close   Adj Close\n",
      "Date                                                                  \n",
      "2019-12-11   86.260002   86.870003   85.849998   86.589996   84.145752\n",
      "2019-12-12   88.000000   88.889999   87.540001   88.209999   85.720032\n",
      "2019-12-13   88.019997   88.790001   87.580002   88.669998   86.167046\n",
      "2019-12-16   89.139999   89.300003   88.430000   88.779999   86.273941\n",
      "2019-12-17   88.870003   88.970001   87.470001   88.129997   85.642288\n",
      "...                ...         ...         ...         ...         ...\n",
      "2020-12-04  101.349998  102.940002  101.070000  102.279999  101.442787\n",
      "2020-12-07  102.010002  102.220001  100.690002  101.410004  100.579918\n",
      "2020-12-08  100.370003  101.570000  100.010002  101.209999  100.381554\n",
      "2020-12-09  101.940002  102.209999  100.099998  100.400002   99.578186\n",
      "2020-12-10  103.510002  106.089996  102.750000  105.389999  104.527336\n",
      "\n",
      "[253 rows x 5 columns]                 Volume\n",
      "Date                  \n",
      "2019-12-11   4921900.0\n",
      "2019-12-12  10282100.0\n",
      "2019-12-13   6714100.0\n",
      "2019-12-16   6705600.0\n",
      "2019-12-17   7296900.0\n",
      "...                ...\n",
      "2020-12-04   6952700.0\n",
      "2020-12-07   4514800.0\n",
      "2020-12-08   3911300.0\n",
      "2020-12-09   6629900.0\n",
      "2020-12-10  12939200.0\n",
      "\n",
      "[253 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "X = data.iloc[:, :-1]\n",
    "y = data.iloc[:, 5:6]\n",
    "print(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db5cea36-7afe-4816-8ca7-9e7b384b3163",
   "metadata": {},
   "outputs": [],
   "source": [
    "ms = MinMaxScaler()\n",
    "ss = StandardScaler()\n",
    "\n",
    "X_ss = ss.fit_transform(X)\n",
    "y_ms = ms.fit_transform(y)\n",
    "\n",
    "X_train = X_ss[:200, :]\n",
    "X_test = X_ss[:53, :]\n",
    "\n",
    "y_train = y_ms[:200, :]\n",
    "y_test = y_ms[:53, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "095b5c0f-3e11-49ec-86c4-01d86200e2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(X_ss, y_ms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c300ef5-f246-42c0-a3af-49cda6ed3fbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 5) (53, 5) (200, 1) (53, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd93e4a-4aec-44f8-82f7-c5546bdd766d",
   "metadata": {},
   "source": [
    "## 파이토치 관련\n",
    "- 데이터를 텐서로 변경\n",
    "- 모델 설계\n",
    "- 모델 생성 후 학습\n",
    "- 예측\n",
    "- 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46199255-6380-4772-abc4-9d4219c70569",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensors = Variable(torch.Tensor(X_train))\n",
    "X_test_tensors = Variable(torch.Tensor(X_test))\n",
    "y_train_tensors = Variable(torch.Tensor(y_train))\n",
    "y_test_tensors = Variable(torch.Tensor(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60ddbcff-827c-48e2-8d54-ffb3c3ce55de",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train_tensor_f' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m X_test_tensors_f \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mreshape(X_test_tensors, (X_test_tensors\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m1\u001b[39m, X_test_tensors\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]))\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# reshape하는 과정이나 이유에 대해서 아래쪽에서 설명\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28mprint\u001b[39m(X_train_tensors\u001b[38;5;241m.\u001b[39mshape, \u001b[43mX_train_tensor_f\u001b[49m\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train_tensor_f' is not defined"
     ]
    }
   ],
   "source": [
    "# 주의!\n",
    "X_train_tensors_f = torch.reshape(X_train_tensors, (X_train_tensors.shape[0], 1, X_train_tensors.shape[1]))\n",
    "X_test_tensors_f = torch.reshape(X_test_tensors, (X_test_tensors.shape[0], 1, X_test_tensors.shape[1]))\n",
    "\n",
    "# reshape하는 과정이나 이유에 대해서 아래쪽에서 설명\n",
    "print(X_train_tensors.shape, X_train_tensor_f.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8910f4-90bc-4e87-a6fe-be060e637d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    # 모델은 이렇게 작성해야 하나요?\n",
    "        # 생성자 부터 작성 => \"하이퍼 파라미터\"\n",
    "        # 순전파 작성\n",
    "        # 역전파는 작성하지 않음\n",
    "    def __init__(self, num_classes, input_size, hidden_size, num_layers, seq_length):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.seq_length = seq_length\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "        self.fc_1 = nn_Linear(hidden_size, 128)\n",
    "        self.fc = nn.Linear(128, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        h_0 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size)) # 1, 3, 20\n",
    "        c_0 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size))\n",
    "\n",
    "        output, (hn, cn) = self.lstm(x, (h_0, c_0))\n",
    "        hn = hn.view(-1, self.hidden_size)\n",
    "        out = self.relu(self.hn)\n",
    "        out = self.fc_1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "89aee19b-e0da-494b-9195-3f8618855312",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 1000\n",
    "learning_rate = 0.0001 # optimizer 오차를 적절하게 반복\n",
    "\n",
    "input_size = 5\n",
    "hidden_size = 2\n",
    "num_layers = 1\n",
    "num_classes = 1\n",
    "\n",
    "model = LSTM(num_classes, input_size, hidden_size, num_layers, X_train_tensors_f.shape[1])\n",
    "\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "00f122ed-bf12-4475-9e14-2992d1adf6d0",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "input.size(-1) must be equal to input_size. Expected 1, got 5",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[1;32m----> 2\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_tensors_f\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m      4\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(outputs, y_train_tensors)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\torch-book\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:898\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    894\u001b[0m     c_zeros \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers \u001b[38;5;241m*\u001b[39m num_directions,\n\u001b[0;32m    895\u001b[0m                           max_batch_size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_size,\n\u001b[0;32m    896\u001b[0m                           dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdtype, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    897\u001b[0m     hx \u001b[38;5;241m=\u001b[39m (h_zeros, c_zeros)\n\u001b[1;32m--> 898\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_forward_args\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_sizes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    899\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    900\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_batched:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\torch-book\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:827\u001b[0m, in \u001b[0;36mLSTM.check_forward_args\u001b[1;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[0;32m    822\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_forward_args\u001b[39m(\u001b[38;5;28mself\u001b[39m,  \u001b[38;5;66;03m# type: ignore[override]\u001b[39;00m\n\u001b[0;32m    823\u001b[0m                        \u001b[38;5;28minput\u001b[39m: Tensor,\n\u001b[0;32m    824\u001b[0m                        hidden: Tuple[Tensor, Tensor],\n\u001b[0;32m    825\u001b[0m                        batch_sizes: Optional[Tensor],\n\u001b[0;32m    826\u001b[0m                        ):\n\u001b[1;32m--> 827\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_sizes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    828\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_hidden_size(hidden[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_expected_hidden_size(\u001b[38;5;28minput\u001b[39m, batch_sizes),\n\u001b[0;32m    829\u001b[0m                            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExpected hidden[0] size \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    830\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_hidden_size(hidden[\u001b[38;5;241m1\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_expected_cell_size(\u001b[38;5;28minput\u001b[39m, batch_sizes),\n\u001b[0;32m    831\u001b[0m                            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExpected hidden[1] size \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\torch-book\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:246\u001b[0m, in \u001b[0;36mRNNBase.check_input\u001b[1;34m(self, input, batch_sizes)\u001b[0m\n\u001b[0;32m    243\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    244\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput must have \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexpected_input_dim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m dimensions, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    245\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_size \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m--> 246\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    247\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput.size(-1) must be equal to input_size. Expected \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: input.size(-1) must be equal to input_size. Expected 1, got 5"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    outputs = model.forward(X_train_tensors_f)\n",
    "    optimizer.zero_grad()\n",
    "    loss = criterion(outputs, y_train_tensors)\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "    if epoch % 100 == 0:\n",
    "        print(\"Epoch: %d, loss: %1.5f\" % (epoch, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88860889-bb61-407b-a128-a21a359c730a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
