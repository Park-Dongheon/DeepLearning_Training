import torch
import torch.nn as nn

import os
from pathlib import Path


from torchvision.datasets import MNIST, FashionMNIST, CIFAR10
import torchvision.transforms.v2 as v2


dataset = MNIST('data', download=True, transform=v2.ToTensor())
dataset = FashionMNIST('data', download=True, transform=v2.ToTensor())
dataset = CIFAR10('data', download=True, transform=v2.ToTensor())


dataset.data.shape


from torch.utils.data import DataLoader


data_loader = DataLoader(dataset, batch_size=64)


50000 / 64


for X_train, y_label in data_loader:
    print(X_train.shape, y_label.shape)
    break


class LeNet5(nn.Module):
    def __init__(self):
        super(LeNet5, self).__init__()
        self.features = nn.Sequential(
            nn.Conv2d(3, 6, 5, padding='same'),
            nn.ReLU(),
            nn.Dropout(),
            nn.MaxPool2d(2),
            nn.Conv2d(6, 16, 5, padding='same'),
            nn.ReLU(),
            nn.Dropout(),
            nn.MaxPool2d(2),
            nn.Conv2d(16, 126, 5, padding='same'),
            nn.ReLU(),
            nn.Dropout(),
            nn.MaxPool2d(2),            
        )
        self.flatten = nn.Flatten()
        self.classifier = nn.Sequential(
            nn.Linear(126 * 4 * 4, 128),
            nn.ReLU(),
            nn.Linear(128, 64),
            nn.ReLU(),
            nn.Linear(64, 10),
            nn.Softmax(dim=1)
        )

    def forward(self, x):
        x = self.features(x)
        #print(x.shape)
        x = self.flatten(x)
        x = self.classifier(x)
        return x


model = LeNet5()


color_image = torch.rand(64, 3, 32, 32)
model(color_image).shape


for X_train, y_label in data_loader:
    model(X_train)
    break


loss_fn = nn.CrossEntropyLoss()


import torch.optim as optim
optimizer = optim.Adam(model.parameters(), lr=0.001)


for X_train, y_label in data_loader:
    optimizer.zero_grad()
    outputs = model(X_train)
    loss = loss_fn(outputs, y_label)
    loss.backward()
    optimizer.step()
    break


dataset = MNIST('data', download=True, transform=v2.ToTensor())


data, label = dataset[0]


data.shape, type(label)


from PIL import Image
import torchvision.transforms.v2 as v2

class MyDataset():
    def __init__(self, root='./data/dogs-vs-cats', transform=None):
        self.root = root
        self.image_paths = []
        self.__classes = {'Cat': 0, 'Dog': 1}
        self.labels = []
        
        for dname in os.listdir(self.root):
            print(type(dname))
            print(os.path.isdir(Path(root, dname)))
            new_path = Path(root, dname)
            if os.path.isdir(new_path):
                for file in os.listdir(new_path):
                    #print(file)
                    self.image_paths.append(str(Path(new_path, file)))
                    self.labels.append(self.__classes[dname])
        
        self.transform = transform
        
    def __getitem__(self, idx):
        path = self.image_paths[idx]
        #print(path)
        image = Image.open(path)
        #print(self.transform(image).shape)
        return self.transform(image) , self.labels[idx]

    def __len__(self):
        return len(self.labels)


transform = v2.Compose([ 
             v2.RandomResizedCrop(size=(224, 224), antialias=True),
             v2.ToTensor(),
             v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])
dataset = MyDataset('./data/dogs-vs-cats', transform)
data, label = dataset[0]
data.shape, label


data_loader = DataLoader(dataset, batch_size=32, shuffle=True)


for X_train, y_label in data_loader:
    print(X_train.shape, y_label.shape)
    break


class LeNet5(nn.Module):
    def __init__(self):
        super(LeNet5, self).__init__()
        self.features = nn.Sequential(
            nn.Conv2d(3, 6, 5, padding='same'),
            nn.ReLU(),
            nn.Dropout(),
            nn.MaxPool2d(2),
            nn.Conv2d(6, 16, 5, padding='same'),
            nn.ReLU(),
            nn.Dropout(),
            nn.MaxPool2d(2),
            nn.Conv2d(16, 32, 5, padding='same'),
            nn.ReLU(),
            nn.Dropout(),
            nn.MaxPool2d(2),            
        )
        self.flatten = nn.Flatten()
        self.classifier = nn.Sequential(
            nn.Linear(32 * 28 * 28, 128),
            #nn.Linear(98784, 128),
            nn.Dropout(),
            nn.ReLU(),
            nn.Linear(128, 64),
            nn.Dropout(),
            nn.ReLU(),
            nn.Linear(64, 2),
            nn.Softmax(dim=1)
        )

    def forward(self, x):
        x = self.features(x)
        #print(x.shape)
        x = self.flatten(x)
        x = self.classifier(x)
        return x


model = LeNet5()
color_image = torch.rand(32, 3, 224, 224)
model(color_image).shape


for X_train, y_label in data_loader:
    outputs = model(X_train)
    print(outputs.shape)
    break


loss_fn = nn.CrossEntropyLoss()


pip install torch-summary


from torchsummary import summary

summary(model, (3, 224, 224))


model = LeNet5()
import torch.optim as optim
optimizer = optim.Adam(model.parameters(), lr=0.0001)


for X_train, y_label in data_loader:
    optimizer.zero_grad()
    outputs = model(X_train)
    loss = loss_fn(outputs, y_label)
    loss.backward()
    optimizer.step()
    break


EPOCHS  = 1
for n in range(EPOCHS ):
    print('EPOCH {}:'.format(n + 1))
    epoch_loss = 0
    step_loss = 0
    for idx, (X_train, y_label) in enumerate(data_loader):
        optimizer.zero_grad()
        outputs = model(X_train)
        loss = loss_fn(outputs, y_label)
        loss.backward()
        optimizer.step()
        step_loss += loss.item()
        #if idx % 5 == 0:
        #epoch_loss = step_loss / len(X_train) # loss per batch
        print('  batch {} loss: {}'.format(idx + 1, step_loss))
        step_loss = 0


from torch.utils.data import random_split

train_dataset, test_dataset = random_split(dataset, [0.8, 0.2])
len(train_dataset), len(test_dataset)


train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=32, shuffle=True)

for X_train, y_label in train_loader:
    print(X_train.shape, y_label.shape)
    break


model = LeNet5()
import torch.optim as optim
optimizer = optim.Adam(model.parameters(), lr=0.0001)


EPOCHS  = 1
for n in range(EPOCHS ):
    print('EPOCH {}:'.format(n + 1))
    epoch_loss = 0
    step_loss = 0
    for idx, (X_train, y_label) in enumerate(data_loader):
        optimizer.zero_grad()
        outputs = model(X_train)
        loss = loss_fn(outputs, y_label)
        loss.backward()
        optimizer.step()
        step_loss += loss.item()
        #print(torch.argmax(outputs, dim=1))
        #print(y_label)
        train_acc = torch.sum(torch.argmax(outputs, dim=1) == y_label)
        #if idx % 5 == 0:
        #epoch_loss = step_loss / len(X_train) # loss per batch
        print('  batch {} loss: {}, acc: {}'.format(idx + 1, step_loss, train_acc/len(X_train)))
        step_loss = 0


from torchvision.datasets import ImageFolder
my_transform = v2.Compose([
    v2.Resize(size=(224, 224)),
    v2.ToTensor()])

dataset = ImageFolder('./data/dogs-vs-cats', transform=my_transform)
image, label = dataset[0]
type(image), type(label)


from torch.utils.data import DataLoader

data_loader = DataLoader(dataset, batch_size=32)
for X_train, y_label in data_loader:
    print(X_train.shape, y_label.shape)
    break


from torchvision.models import resnet50, ResNet50_Weights

# Old weights with accuracy 76.130%
resnet50(weights=ResNet50_Weights.IMAGENET1K_V1)

# New weights with accuracy 80.858%
resnet50(weights=ResNet50_Weights.IMAGENET1K_V2)

# Best available weights (currently alias for IMAGENET1K_V2)
# Note that these weights may change across versions
resnet50(weights=ResNet50_Weights.DEFAULT)

# Strings are also supported
resnet50(weights="IMAGENET1K_V2")

# No weights - random initialization
model = resnet50(weights=None)
model


from torch.utils.data import DataLoader

data_loader = DataLoader(dataset, batch_size=32)
for X_train, y_label in data_loader:
    outputs = model(X_train)
    print(outputs.shape)
    break


import os
from pathlib import Path

root = './data/dogs-vs-cats'
image_paths = []
labels = []

for dname in os.listdir(root):
    print(dname)


import os
from pathlib import Path

root = './data/dogs-vs-cats'
image_paths = []
labels = []

for dname in os.listdir(root):
    print(type(dname))
    print(os.path.isdir(Path(root, dname)))
    new_path = Path(root, dname)
    if os.path.isdir(new_path):
        for file in os.listdir(new_path):
            #print(file)
            image_paths.append(str(Path(new_path, file)))
            labels.append(dname)
len(image_paths), len(labels), labels.count('Cat'), labels.count('Dog')


from torchvision.utils import make_grid
import torchvision.transforms.v2 as v2

to_pil = v2.ToPILImage()
for X_train, y_label in data_loader:
    grid_images = make_grid(X_train, nrow=8)
    pil_grid_images = to_pil(grid_images)
    break
pil_grid_images


import requests

url = 'https://raw.githubusercontent.com/pytorch/vision/main/gallery/assets/astronaut.jpg'
response = requests.get(url)
response.content


from PIL import Image
import io

img = Image.open(io.BytesIO(response.content))
img



