import torch
import torch.nn as nn
torch.__version__


torch.cuda.is_available()


from torchvision.models import alexnet, AlexNet_Weights


model = alexnet(weights=AlexNet_Weights.IMAGENET1K_V1)
model


for p in model.parameters():
    #print(p.names, type(p), p.shape, p.requires_grad)
    p.requires_grad = False


summary(model, (3, 224, 224))


model.classifier = nn.Sequential(
    nn.Dropout(),
    nn.Linear(9216, 64),
    nn.ReLU(),
    nn.Linear(64, 2),
    nn.Softmax(dim=1)
)
model


pip install torch-summary


summary(model, (3, 224, 224))


image = torch.rand(32, 3, 224, 224)
model(image).shape


for p in model.parameters():
    print(p.names, type(p), p.shape, p.requires_grad)


from torchvision.datasets import ImageFolder


import torchvision.transforms.v2 as v2


my_transform = v2.Compose([
    v2.Resize((224, 224)),
    v2.ToTensor()
])
root = 'data/dogs-vs-cats'
dataset = ImageFolder(root, transform=my_transform)


from torch.utils.data import DataLoader


def fit(model, data_loader, loss_fn, optimizer, epochs):
    for i in range(epochs):
        for X_train, y_label in data_loader:
            optimizer.zero_grad()
            outputs = model(X_train)
            loss = loss_fn(outputs, y_label)
            loss.backward()
            optimizer.step()
    return model


data_loader = DataLoader(dataset, batch_size=32, shuffle=True)
for X_train, y_label in data_loader:
    print(X_train.shape, y_label.shape)
    break


#fit(model, data_loader, loss_fn, optimizer, 1)


for X_train, y_label in data_loader:
    optimizer.zero_grad()
    outputs = model(X_train)
    loss = loss_fn(outputs, y_label)
    loss.backward()
    optimizer.step()
    break


from torchvision.models import resnet50, ResNet50_Weights


model = resnet50(weights=ResNet50_Weights.IMAGENET1K_V2)


model


for p in model.parameters():
    p.requires_grad = False


model.fc = nn.Sequential(
    nn.Linear(2048, 512),
    nn.ReLU(True),
    nn.Dropout(),
    nn.Linear(512, 32),
    nn.ReLU(True),
    nn.Dropout(),
    nn.Linear(32, 2),
    )
model


train_transform = v2.Compose([
    v2.Resize((256, 256)),
    v2.RandomResizedCrop(size=(224, 224), antialias=True),
    v2.RandomHorizontalFlip(p=0.5),
    v2.RandomVerticalFlip(p=0.5),
    v2.ToTensor(),
    v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])

test_transform = v2.Compose([
    v2.Resize((256, 256)),
    v2.CenterCrop(size=(224, 224)),
    v2.ToTensor(),
    v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])


train_path = 'data/catanddog/train'
train_dataset = ImageFolder(train_path, transform=train_transform)


test_path = 'data/catanddog/test'
test_dataset = ImageFolder(test_path, transform=test_transform)


from torch.utils.data import DataLoader


train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=32, shuffle=True)


def train(model, data_loader, loss_fn, optimizer, EPOCHS=1):
    loss_history = []
    acc_history = []
    epoch_loss = 0.
    num_corrects = 0
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    for n in range(EPOCHS):
        step_loss = 0
        num_corrects = 0
        for idx, (X_train, y_label) in enumerate(data_loader):
            inputs = X_train.to(device)
            labels = y_label.to(device)
            model = model.to(device)
            optimizer.zero_grad()
            outputs = model(inputs)
            loss = loss_fn(outputs, labels)
            loss.backward()
            optimizer.step()
            step_loss += loss.item()
            #print(torch.argmax(outputs, dim=1))
            #print(y_label)
            train_acc = torch.sum(torch.argmax(outputs, dim=1) == labels)
            num_corrects += train_acc
            #if idx % 5 == 0:
            #epoch_loss = step_loss / len(X_train) # loss per batch
            #print('  batch {} loss: {}, acc: {}'.format(idx + 1, step_loss, train_acc/len(X_train)))
            #step_loss = 0
        epoch_loss = step_loss / len(data_loader)
        accuracy = num_corrects / len(data_loader.dataset)
        print('EPOCH {}, loss: {}, acc: {}'.format(n + 1, epoch_loss, accuracy))
    #return model


import torch.optim as optim

loss_fn = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters())


train(model, train_loader, loss_fn, optimizer, 5)


from torchvision.models import list_models


list_models()


from torchvision.models import alexnet, AlexNet_Weights


model = alexnet(weights=AlexNet_Weights.IMAGENET1K_V1)
model


summary(model, (3, 224, 224))


type(model.classifier), type(model.classifier.parameters())


for p in model.parameters():
    print(type(p), p.shape, p.requires_grad)
    p.requires_grad = False


for p in model.parameters():
    print(type(p), p.shape, p.requires_grad)


for p in model.classifier.parameters():
    print(type(p), p.shape, p.requires_grad)


256 * 6 * 6


import torch
import torch.nn as nn

model.classifier = nn.Sequential(
    nn.Dropout(),
    nn.Linear(9216, 64),
    nn.ReLU(),
    nn.Linear(64, 2),
    nn.Softmax(dim=1)
)
model


summary(model, (3, 224, 224))


image = torch.rand(32, 3, 224, 224)
model(image).shape





from torchvision.models import vgg16, VGG16_Weights


model = vgg16(weights=VGG16_Weights.IMAGENET1K_V1)
model


model.classifier = nn.Sequential(
    nn.Linear(512 * 7 * 7, 512),
    nn.ReLU(True),
    nn.Dropout(),
    nn.Linear(512, 64),
    nn.ReLU(True),
    nn.Dropout(),
    nn.Linear(64, 2),
)


summary(model, (3, 224, 224))


for p in model.parameters():
    #print(type(p), p.shape, p.requires_grad)
    p.requires_grad = False


512 *  7 * 7


model.classifier = nn.Sequential(
    nn.Linear(512 * 7 * 7, 1024),
    nn.ReLU(),
    nn.Dropout(),
    nn.Linear(1024, 2)
)
model


image = torch.rand(32, 3, 224, 224)
model(image).shape


summary(model, (3, 224, 224))


from PIL import Image
import torchvision.transforms.v2 as v2

image = Image.open('./data/dogs-vs-cats/Cat/cat.1.jpg')
to_tensor = v2.Compose([
    v2.Resize((224, 224)),
    v2.ToTensor()])
tensor_image = to_tensor(image)
tensor_image[None, :, :, :].shape
tensor_image = torch.unsqueeze(tensor_image, dim=0)
tensor_image.shape


model(tensor_image)



