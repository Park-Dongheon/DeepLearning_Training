


import os
import io
import requests
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.transforms.v2 as v2
from torchsummary import summary
from torch.utils.data import DataLoader
from torch.utils.data import random_split
from torchvision.utils import make_grid
from torchvision.datasets import ImageFolder
from torchvision.datasets import MNIST, FashionMNIST, CIFAR10
from torchvision.models import resnet50, ResNet50_Weights
from PIL import Image
from pathlib import Path


dataset = FashionMNIST('data', download=True, transform=v2.ToTensor())
dataset = CIFAR10('data', download=True, transform=v2.ToTensor())


dataset.data.shape


data_loader = DataLoader(dataset, batch_size=64)


50000 / 64


for X_train, y_label in data_loader:
    print(X_train.shape, y_label.shape)
    break


class LeNet5(nn.Module):
    def __init__(self):
        super(LeNet5, self).__init__()
        self.features = nn.Sequential(
            nn.Conv2d(3, 6, 5, padding='same'),
            nn.ReLU(),
            nn.Dropout(),
            nn.MaxPool2d(2),
            nn.Conv2d(6, 16, 5, padding='same'),
            nn.ReLU(),
            nn.Dropout(),
            nn.MaxPool2d(2),
            nn.Conv2d(16, 126, 5, padding='same'),
            nn.ReLU(),
            nn.Dropout(),
            nn.MaxPool2d(2),
        )
        self.flatten = nn.Flatten()
        self.classifier = nn.Sequential(
            nn.Linear(126 * 4 * 4, 128),
            nn.ReLU(),
            nn.Linear(128, 64),
            nn.ReLU(),
            nn.Linear(64, 10),
            nn.Softmax(dim=1)
        )

    def forward(self, x):
        x = self.features(x)
        x = self.flatten(x)
        x = self.classifier(x)
        return x


model = LeNet5()


color_image = torch.rand(64, 3, 32, 32)
model(color_image).shape


for X_train, y_label in data_loader:
    model(X_train)
    break


loss_fn = nn.CrossEntropyLoss()


optimizer = optim.Adam(model.parameters(), lr=0.001)


for X_train, y_label in data_loader:
    optimizer.zero_grad()
    outputs = model(X_train)
    loss = loss_fn(outputs, y_label)
    loss.backward()
    optimizer.step()
    break


dataset = MNIST('data', download=True, transform=v2.ToTensor())


data, label = dataset[0]
data.shape, type(label)


class MyDataset():
    def __init__(self, root='./data/dogs-vs-cats', transform=None):
        self.root = root
        self.image_paths = []
        self.__classes = {'Cat':0, 'Dog':1}
        self.labels = []

        for dname in os.listdir(self.root):
            print(type(dname))
            print(os.path.isdir(Path(root, dname)))
            new_path = Path(root, dname)
            if os.path.isdir(new_path):
                for file in os.listdir(new_path):
                    # print(file)
                    self.image_paths.append(str(Path(new_path, file)))
                    self.labels.append(self.__classes[dname])
                    
        self.transform = transform

    def __getitem__(self, idx):
        path = self.image_paths[idx]
        # print(path)
        image = Image.open(path)
        # print(self.transform(image).shape)
        return self.transform(image), self.labels[idx]

    def __len__(self):
        return len(self.labels)


transform = v2.Compose([
            v2.RandomResizedCrop(size=(224,224), antialias=True),
            v2.ToTensor(),
            v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])
dataset = MyDataset('./data/dogs-vs-cats', transform)
data, label = dataset[0]
data.shape, label


data_loader = DataLoader(dataset, batch_size=32, shuffle=True)

for X_train, y_label in data_loader:
    print(X_train.shape, y_label.shape)
    break


class LeNet5(nn.Module):
    def __init__(self):
        super(LeNet5, self).__init__()
        self.features = nn.Sequential(
            nn.Conv2d(3, 6, 5, padding='same'),
            nn.ReLU(),
            nn.Dropout(),
            nn.MaxPool2d(2),
            nn.Conv2d(6, 16, 5, padding='same'),
            nn.ReLU(),
            nn.Dropout(),
            nn.MaxPool2d(2),
            nn.Conv2d(16, 32, 5, padding='same'),
            nn.ReLU(),
            nn.Dropout(),
            nn.MaxPool2d(2),
        )
        self.flatten = nn.Flatten()
        self.classifier = nn.Sequential(
            nn.Linear(32 * 28 * 28, 128),
            # nn.Linear(98784, 128),
            nn.ReLU(),
            nn.Linear(128, 64),
            nn.ReLU(),
            nn.Linear(64, 2),
            nn.Softmax(dim=1)
        )

    def forward(self, x):
        x = self.features(x)
        x = self.flatten(x)
        x = self.classifier(x)
        return x


model = LeNet5()
color_image = torch.rand(32, 3, 224, 224)
model(color_image).shape


for X_train, y_label in data_loader:
    outputs = model(X_train)
    print(outputs.shape)
    break


loss_fn = nn.CrossEntropyLoss()


summary(model, (3, 224, 224))


optimizer = optim.Adam(model.parameters(), lr=0.0001)

for X_train, y_label in data_loader:
    optimizer.zero_grad()
    outputs = model(X_train)
    loss = loss_fn(outputs, y_label)
    loss.backward()
    optimizer.step()
    break


EPOCHS = 1

for n in range(EPOCHS):
    print('EPOCHS {}:'.format(n + 1))
    epoch_loss = 0
    step_loss = 0
    for idx, (X_train, y_label) in enumerate(data_loader):
        optimizer.zero_grad()
        outputs = model(X_train)
        loss = loss_fn(outputs, y_label)
        loss.backward()
        optimizer.step()
        step_loss += loss.item()
        # if idx % 5 == 0:
        # epoch_loss = step_loss / len(X_train) # loss per batch
        print(' batch {} loss: {}'.format(idx + 1, step_loss))
        step_loss = 0


train_dataset, test_dataset = random_split(dataset, [0.8, 0.2])
len(train_dataset), len(test_dataset)


train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=32, shuffle=True)

for X_train, y_label in train_loader:
    print(X_train.shape, y_label.shape)
    break


optimizer = optim.Adam(model.parameters(), lr=0.0001)

EPOCHS = 1
for n in range(EPOCHS):
    print('EPOCHS {}:'.format(n + 1))
    epoch_loss = 0
    step_loss = 0
    for idx, (X_train, y_label) in enumerate(data_loader):
        optimizer.zero_grad()
        outputs = model(X_train)
        loss = loss_fn(outputs, y_label)
        loss.backward()
        optimizer.step()
        step_loss += loss.item()
        # print(torch.argmax(outputs, dim=1))
        # print(y_label)
        train_acc = torch.sum(torch.argmax(outputs, dim=1) == y_label)
        # if idx % 5 == 0:
        # epoch_loss = step_loss / len(X_train) # loss per batch
        print(' batch {} loss: {}, acc: {}'.format(idx + 1, step_loss, train_acc / len(X_train)))
        step_loss = 0


my_transform = v2.Compose([
              v2.Resize(size=(224, 224)),
              v2.ToTensor()
])
dataset = ImageFolder('./data/dogs-vs-cats', transform=my_transform)
image, label = dataset[0]
type(image), type(label)


data_loader = DataLoader(dataset, batch_size=32)
for X_train, y_label in data_loader:
    print(X_train.shape, y_label.shape)
    break


# Old weights with accuracy 76.130%
resnet50(weights=ResNet50_Weights.IMAGENET1K_V1)

# New weights with accuracy 80.858%
resnet50(weights=ResNet50_Weights.IMAGENET1K_V2)

# Best available weights (currently alias for IMAGENET1K_V2)
# Note that these weights may change across versions
resnet50(weights=ResNet50_Weights.DEFAULT)

# Strings are also supported
resnet50(weights="IMAGENET1K_V2")

# No weights - random initialization
model = resnet50(weights=None)
model


data_loader = DataLoader(dataset, batch_size=32)
for X_train, y_label in data_loader:
    outputs = model(X_train)
    print(outputs.shape)
    break


root = './data/dogs-vs-cats'
image_paths = []
labels = []

for dname in os.listdir(root):
    print(dname)


root = './data/dogs-vs-cats'
image_paths = []
labels = []

for dname in os.listdir(root):
    print(type(dname))
    print(os.path.isdir(Path(root, dname)))
    new_path = Path(root, dname)
    if os.path.isdir(new_path):
        for file in os.listdir(new_path):
            # print(file)
            image_paths.append(str(Path(new_path, file)))
            labels.append(dname)

len(image_paths), len(labels), labels.count('Cat'), labels.count('Dog')


to_pil = v2.ToPILImage()

for X_train, y_label in data_loader:
    grid_images = make_grid(X_train, nrow=8)
    pil_grid_images = to_pil(grid_images)
    break

pil_grid_images


url = 'https://raw.githubusercontent.com/pytorch/vision/main/gallery/assets/astronaut.jpg'
response = requests.get(url)
response.content


img = Image.open(io.BytesIO(response.content))
img
